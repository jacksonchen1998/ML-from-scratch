{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-09-02T08:35:05.363669Z","iopub.execute_input":"2023-09-02T08:35:05.364011Z","iopub.status.idle":"2023-09-02T08:35:05.368522Z","shell.execute_reply.started":"2023-09-02T08:35:05.363987Z","shell.execute_reply":"2023-09-02T08:35:05.367468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocess","metadata":{}},{"cell_type":"code","source":"# Load the training data from Kaggle\ntrain_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\n# Split the data into features (X) and labels (y)\nX_train = train_data.drop(columns=['label'])\ny_train = train_data['label']\n\n# Split the data into features (X) and labels (y)\nX_test = test_data","metadata":{"execution":{"iopub.status.busy":"2023-09-02T08:35:05.374757Z","iopub.execute_input":"2023-09-02T08:35:05.375120Z","iopub.status.idle":"2023-09-02T08:35:08.110228Z","shell.execute_reply.started":"2023-09-02T08:35:05.375089Z","shell.execute_reply":"2023-09-02T08:35:08.109181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Library from scratch\n- GaussianNB","metadata":{}},{"cell_type":"code","source":"class MultinomialNB:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha  # Laplace smoothing parameter\n        self.class_prior_ = None\n        self.feature_log_prob_ = None\n\n    def fit(self, X, y):\n        # Calculate class priors\n        classes, class_counts = np.unique(y, return_counts=True)\n        self.class_prior_ = class_counts / len(y)\n\n        # Calculate conditional probabilities using Laplace smoothing\n        num_classes = len(classes)\n        num_features = X.shape[1]\n        self.feature_log_prob_ = np.zeros((num_classes, num_features))\n\n        for i, c in enumerate(classes):\n            class_mask = (y == c)\n            class_count = class_counts[i]\n            term_counts = X[class_mask].sum(axis=0)\n            self.feature_log_prob_[i] = np.log((term_counts + self.alpha) / (class_count + self.alpha * num_features))\n\n    def predict(self, X):\n        # Calculate the log probability of each class for each sample\n        log_probs = np.dot(X, self.feature_log_prob_.T) + np.log(self.class_prior_)\n\n        # Select the class with the highest log probability\n        return np.argmax(log_probs, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T08:35:08.112618Z","iopub.execute_input":"2023-09-02T08:35:08.113081Z","iopub.status.idle":"2023-09-02T08:35:08.121974Z","shell.execute_reply.started":"2023-09-02T08:35:08.113044Z","shell.execute_reply":"2023-09-02T08:35:08.120709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"model = MultinomialNB()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = model.predict(X_test)\n\n# Create a DataFrame for the submission\nsubmission = pd.DataFrame({'ImageId': range(1, len(y_pred) + 1), 'Label': y_pred})\n\n# Save the submission DataFrame to a CSV file\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T08:35:08.123318Z","iopub.execute_input":"2023-09-02T08:35:08.123659Z","iopub.status.idle":"2023-09-02T08:35:08.420616Z","shell.execute_reply.started":"2023-09-02T08:35:08.123628Z","shell.execute_reply":"2023-09-02T08:35:08.419748Z"},"trusted":true},"execution_count":null,"outputs":[]}]}